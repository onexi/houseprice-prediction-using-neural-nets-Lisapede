{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lisa's House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4712</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10659</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9786</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6762</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0       1          60       RL         65.0     8450   Pave     0      Reg   \n",
       "1       2          20       RL         80.0     9600   Pave     0      Reg   \n",
       "2       3          60       RL         68.0    11250   Pave     0      IR1   \n",
       "3       4          70       RL         60.0     9550   Pave     0      IR1   \n",
       "4       5          60       RL         84.0    14260   Pave     0      IR1   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "995   996          50       RL         51.0     4712   Pave     0      IR1   \n",
       "996   997          20       RL          0.0    10659   Pave     0      IR1   \n",
       "997   998          20       RL          0.0    11717   Pave     0      IR1   \n",
       "998   999          30       RM         60.0     9786   Pave     0      Reg   \n",
       "999  1000          20       RL         64.0     6762   Pave     0      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0           Lvl    AllPub  ...        0      0      0           0       0   \n",
       "1           Lvl    AllPub  ...        0      0      0           0       0   \n",
       "2           Lvl    AllPub  ...        0      0      0           0       0   \n",
       "3           Lvl    AllPub  ...        0      0      0           0       0   \n",
       "4           Lvl    AllPub  ...        0      0      0           0       0   \n",
       "..          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "995         Lvl    AllPub  ...        0      0  MnPrv           0       0   \n",
       "996         Lvl    AllPub  ...        0      0      0           0       0   \n",
       "997         Lvl    AllPub  ...        0      0      0           0       0   \n",
       "998         Lvl    AllPub  ...        0      0      0           0       0   \n",
       "999         Lvl    AllPub  ...        0      0      0           0       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0        2   2008        WD         Normal     208500  \n",
       "1        5   2007        WD         Normal     181500  \n",
       "2        9   2008        WD         Normal     223500  \n",
       "3        2   2006        WD        Abnorml     140000  \n",
       "4       12   2008        WD         Normal     250000  \n",
       "..     ...    ...       ...            ...        ...  \n",
       "995      8   2006        WD        Abnorml     121600  \n",
       "996      1   2006       COD         Normal     136500  \n",
       "997      2   2009        WD         Normal     185000  \n",
       "998      5   2006        WD         Normal      91000  \n",
       "999      2   2010        WD         Normal     206000  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "#data\n",
    "\n",
    "# ADDED\n",
    "# Preprocess the training data\n",
    "def preprocess_data(df):\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "data_df_processed = preprocess_data(data)\n",
    "data_df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>50</td>\n",
       "      <td>4712</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1946</td>\n",
       "      <td>1950</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>10659</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>11717</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>30</td>\n",
       "      <td>9786</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1922</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>6762</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>686</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       1          60     8450            7            5       2003   \n",
       "1       2          20     9600            6            8       1976   \n",
       "2       3          60    11250            7            5       2001   \n",
       "3       4          70     9550            7            5       1915   \n",
       "4       5          60    14260            8            5       2000   \n",
       "..    ...         ...      ...          ...          ...        ...   \n",
       "995   996          50     4712            4            7       1946   \n",
       "996   997          20    10659            5            6       1961   \n",
       "997   998          20    11717            6            6       1970   \n",
       "998   999          30     9786            3            4       1922   \n",
       "999  1000          20     6762            7            5       2006   \n",
       "\n",
       "     YearRemodAdd  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  WoodDeckSF  \\\n",
       "0            2003         706           0        150  ...           0   \n",
       "1            1976         978           0        284  ...         298   \n",
       "2            2002         486           0        434  ...           0   \n",
       "3            1970         216           0        540  ...           0   \n",
       "4            2000         655           0        490  ...         192   \n",
       "..            ...         ...         ...        ...  ...         ...   \n",
       "995          1950         384           0        363  ...           0   \n",
       "996          1961         915           0        135  ...           0   \n",
       "997          1970           0           0       1442  ...         371   \n",
       "998          1950           0           0       1007  ...           0   \n",
       "999          2006         686           0        501  ...         105   \n",
       "\n",
       "     OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0             61              0          0            0         0        0   \n",
       "1              0              0          0            0         0        0   \n",
       "2             42              0          0            0         0        0   \n",
       "3             35            272          0            0         0        0   \n",
       "4             84              0          0            0         0        0   \n",
       "..           ...            ...        ...          ...       ...      ...   \n",
       "995           57              0          0           63         0        0   \n",
       "996          319              0          0            0         0        0   \n",
       "997            0              0          0            0         0        0   \n",
       "998          100             48          0            0         0        0   \n",
       "999           61              0          0            0         0        0   \n",
       "\n",
       "     MoSold  YrSold  SalePrice  \n",
       "0         2    2008     208500  \n",
       "1         5    2007     181500  \n",
       "2         9    2008     223500  \n",
       "3         2    2006     140000  \n",
       "4        12    2008     250000  \n",
       "..      ...     ...        ...  \n",
       "995       8    2006     121600  \n",
       "996       1    2006     136500  \n",
       "997       2    2009     185000  \n",
       "998       5    2006      91000  \n",
       "999       2    2010     206000  \n",
       "\n",
       "[1000 rows x 35 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in numeric_cols if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")\n",
    "\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original columns: 81\n",
      "Number of columns after clean: 35\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1-2. Confirming Data Cleaning\n",
    "# -----------------------------\n",
    "# Print the number of columns from the dataset\n",
    "print(\"Number of original columns:\", data.shape[1])\n",
    "\n",
    "# Print the number of columns after cleaning\n",
    "print(\"Number of columns after clean:\", data_clean.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "X shape: (1000, 4)\n",
      "y shape: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "#see what the correlation matrix looks like\n",
    "#print(corr_matrix)\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "#view the full list of correlations\n",
    "#print(target_corr)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top4_features = target_corr.head(4).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)\n",
    "\n",
    "# Confirm size of x (variables with highest correlation) and y (target variable = SalePrice)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# NOT SURE ABOUT THIS # Prints out new data_clean\n",
    "#print(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 4)\n",
      "X_test shape: (200, 4)\n",
      "y_train shape: (800, 1)\n",
      "y_test shape: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Confirming sizes of training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# WHAT IS THE PURPOSE OF THE BELOW CODE?\n",
    "# DataLoader is used to load the data in batches. It provides an iterable over the given dataset.\n",
    "# train_loader is created with a batch size of 32 and shuffling enabled, meaning the data will be randomly shuffled at each epoch.\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HousePriceModel(\n",
      "  (fc1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "\n",
    "#HousePriceModel is a subclass of nn.Module, which is the base class for all neural network modules in PyTorch.\n",
    "\n",
    "class HousePriceModel(nn.Module):\n",
    "\n",
    "    #The __init__ method initializes the layers of the network:\n",
    "    def __init__(self, input_dim):\n",
    "    \n",
    "        super(HousePriceModel, self).__init__()\n",
    "        \n",
    "        #self.fc1 is a fully connected layer that takes input_dim features and outputs 64 features.\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  \n",
    "\n",
    "        # self.fc2 is a fully connected layer that takes 64 features and outputs 32 features.\n",
    "        self.fc2 = nn.Linear(64, 32) \n",
    "        \n",
    "        # self.fc3 is a fully connected layer that takes 32 features and outputs 1 feature (the predicted house price).\n",
    "        # Output layer for regression\n",
    "        self.fc3 = nn.Linear(32, 1)  \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    #The forward method defines the forward pass of the network:\n",
    "    def forward(self, x):\n",
    "\n",
    "        #The input x is passed through self.fc1 followed by the ReLU activation, then self.fc2 followed by the ReLU activation, and finally self.fc3.\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "\n",
    "# nn.MSELoss() is a mean squared error (MSE) loss function.\n",
    "# MSE loss is commonly used for regression tasks. It calculates the average squared difference between the \n",
    "# predicted values and the actual target values. The goal during training is to minimize this loss.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optim.Adam is an implementation of the Adam optimization algorithm.\n",
    "# Adam is an adaptive learning rate optimization algorithm that is commonly used for training deep learning models.\n",
    "# lr=0.001 sets the learning rate for the optimizer. \n",
    "# The learning rate controls how much the model's parameters are adjusted with respect to the loss \n",
    "# gradient during each iteration of training.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print to view the criterion and optimizer\n",
    "# criterion\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 40993574338.5600\n",
      "Epoch [20/1000], Loss: 40367486648.3200\n",
      "Epoch [30/1000], Loss: 38663406878.7200\n",
      "Epoch [40/1000], Loss: 35653225758.7200\n",
      "Epoch [50/1000], Loss: 31389868523.5200\n",
      "Epoch [60/1000], Loss: 26206748753.9200\n",
      "Epoch [70/1000], Loss: 20693658214.4000\n",
      "Epoch [80/1000], Loss: 15563029831.6800\n",
      "Epoch [90/1000], Loss: 11390586224.6400\n",
      "Epoch [100/1000], Loss: 8487615569.9200\n",
      "Epoch [110/1000], Loss: 6767097303.0400\n",
      "Epoch [120/1000], Loss: 5842588221.4400\n",
      "Epoch [130/1000], Loss: 5311567964.1600\n",
      "Epoch [140/1000], Loss: 4924692664.3200\n",
      "Epoch [150/1000], Loss: 4586550691.8400\n",
      "Epoch [160/1000], Loss: 4268445122.5600\n",
      "Epoch [170/1000], Loss: 3964022661.1200\n",
      "Epoch [180/1000], Loss: 3672814976.0000\n",
      "Epoch [190/1000], Loss: 3394205557.7600\n",
      "Epoch [200/1000], Loss: 3131757619.2000\n",
      "Epoch [210/1000], Loss: 2884382566.4000\n",
      "Epoch [220/1000], Loss: 2657079157.7600\n",
      "Epoch [230/1000], Loss: 2448325683.2000\n",
      "Epoch [240/1000], Loss: 2264914511.3600\n",
      "Epoch [250/1000], Loss: 2109191815.6800\n",
      "Epoch [260/1000], Loss: 1979811386.8800\n",
      "Epoch [270/1000], Loss: 1877299737.6000\n",
      "Epoch [280/1000], Loss: 1796643760.6400\n",
      "Epoch [290/1000], Loss: 1733893050.8800\n",
      "Epoch [300/1000], Loss: 1686894845.4400\n",
      "Epoch [310/1000], Loss: 1650364948.4800\n",
      "Epoch [320/1000], Loss: 1623310912.0000\n",
      "Epoch [330/1000], Loss: 1600751416.3200\n",
      "Epoch [340/1000], Loss: 1581728035.8400\n",
      "Epoch [350/1000], Loss: 1566804057.6000\n",
      "Epoch [360/1000], Loss: 1555186058.2400\n",
      "Epoch [370/1000], Loss: 1543112624.6400\n",
      "Epoch [380/1000], Loss: 1534128855.0400\n",
      "Epoch [390/1000], Loss: 1525312712.9600\n",
      "Epoch [400/1000], Loss: 1517174492.1600\n",
      "Epoch [410/1000], Loss: 1509173096.9600\n",
      "Epoch [420/1000], Loss: 1502292266.2400\n",
      "Epoch [430/1000], Loss: 1496459466.2400\n",
      "Epoch [440/1000], Loss: 1490812861.4400\n",
      "Epoch [450/1000], Loss: 1485141222.4000\n",
      "Epoch [460/1000], Loss: 1480256536.3200\n",
      "Epoch [470/1000], Loss: 1476051523.8400\n",
      "Epoch [480/1000], Loss: 1471337958.4000\n",
      "Epoch [490/1000], Loss: 1467094064.6400\n",
      "Epoch [500/1000], Loss: 1463370140.1600\n",
      "Epoch [510/1000], Loss: 1459119301.1200\n",
      "Epoch [520/1000], Loss: 1455608655.3600\n",
      "Epoch [530/1000], Loss: 1452670324.4800\n",
      "Epoch [540/1000], Loss: 1451300445.4400\n",
      "Epoch [550/1000], Loss: 1445680349.4400\n",
      "Epoch [560/1000], Loss: 1443082232.3200\n",
      "Epoch [570/1000], Loss: 1440254813.4400\n",
      "Epoch [580/1000], Loss: 1437988451.8400\n",
      "Epoch [590/1000], Loss: 1435367482.8800\n",
      "Epoch [600/1000], Loss: 1432345112.3200\n",
      "Epoch [610/1000], Loss: 1430329128.9600\n",
      "Epoch [620/1000], Loss: 1428571914.2400\n",
      "Epoch [630/1000], Loss: 1426802808.3200\n",
      "Epoch [640/1000], Loss: 1425092131.8400\n",
      "Epoch [650/1000], Loss: 1424766211.8400\n",
      "Epoch [660/1000], Loss: 1420656960.0000\n",
      "Epoch [670/1000], Loss: 1419668231.6800\n",
      "Epoch [680/1000], Loss: 1417216739.8400\n",
      "Epoch [690/1000], Loss: 1416168439.0400\n",
      "Epoch [700/1000], Loss: 1414447376.6400\n",
      "Epoch [710/1000], Loss: 1412501749.7600\n",
      "Epoch [720/1000], Loss: 1411586821.1200\n",
      "Epoch [730/1000], Loss: 1411586103.0400\n",
      "Epoch [740/1000], Loss: 1408554886.4000\n",
      "Epoch [750/1000], Loss: 1408350545.9200\n",
      "Epoch [760/1000], Loss: 1406853530.8800\n",
      "Epoch [770/1000], Loss: 1406280990.7200\n",
      "Epoch [780/1000], Loss: 1404614684.1600\n",
      "Epoch [790/1000], Loss: 1406233940.4800\n",
      "Epoch [800/1000], Loss: 1402891563.5200\n",
      "Epoch [810/1000], Loss: 1402647279.3600\n",
      "Epoch [820/1000], Loss: 1400989777.9200\n",
      "Epoch [830/1000], Loss: 1399827317.7600\n",
      "Epoch [840/1000], Loss: 1399133918.7200\n",
      "Epoch [850/1000], Loss: 1398092902.4000\n",
      "Epoch [860/1000], Loss: 1397729102.0800\n",
      "Epoch [870/1000], Loss: 1397629258.2400\n",
      "Epoch [880/1000], Loss: 1396342097.9200\n",
      "Epoch [890/1000], Loss: 1395713529.6000\n",
      "Epoch [900/1000], Loss: 1394341017.6000\n",
      "Epoch [910/1000], Loss: 1393897521.9200\n",
      "Epoch [920/1000], Loss: 1393785576.9600\n",
      "Epoch [930/1000], Loss: 1392767562.2400\n",
      "Epoch [940/1000], Loss: 1392438312.9600\n",
      "Epoch [950/1000], Loss: 1392178664.9600\n",
      "Epoch [960/1000], Loss: 1391505529.6000\n",
      "Epoch [970/1000], Loss: 1392428578.5600\n",
      "Epoch [980/1000], Loss: 1390494973.4400\n",
      "Epoch [990/1000], Loss: 1389152616.9600\n",
      "Epoch [1000/1000], Loss: 1390861201.9200\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "\n",
    "# num_epochs is set to 1000, meaning the training loop will run for 1000 iterations.\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "# This is the training loop that iterates over the dataset for the specified number of epochs.\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # The model is set to training mode using model.train() before the loop starts.\n",
    "    model.train()\n",
    "    \n",
    "    # The running_loss variable is used to keep track of the total loss during training.\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # This loop iterates over the batches of data provided by train_loader.\n",
    "    # batch_X and batch_y are moved to the specified device (GPU or CPU).\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        # The loss is calculated using the criterion (MSELoss) between the model's predictions outputs and the actual targets batch_y.\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    # The loss is printed every 10 epochs to monitor the training progress.\n",
    "    # At the end of each epoch, the average loss is computed and printed.\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 936112320.0\n",
      "Test MSE (scikit-learn): 936112320.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "\n",
    "# model.eval() sets the model to evaluation mode. This is necessary because some layers \n",
    "# (like dropout and batch normalization) behave differently during training and evaluation.\n",
    "model.eval()\n",
    "\n",
    "# with torch.no_grad(): disables gradient calculation. This is useful for inference because \n",
    "# it reduces memory consumption and speeds up computations.\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "#Test Mean Squared Error: 935741376.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_df = pd.read_csv('test.csv')\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Preprocess the test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_df_processed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m(test_df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure the test data has the same columns as the training data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df_processed\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(test_df_processed\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess the test data\n",
    "test_df_processed = preprocess_data(test_df)\n",
    "\n",
    "# Ensure the test data has the same columns as the training data\n",
    "missing_cols = set(test_df_processed.columns) - set(test_df_processed.columns)\n",
    "for col in missing_cols:\n",
    "    test_df_processed[col] = 0\n",
    "test_df_processed = test_df_processed[test_df_processed.columns.drop('SalePrice')]\n",
    "\n",
    "# Standardize the test data\n",
    "X_test_scaled = scaler.transform(test_df_processed)\n",
    "\n",
    "# Convert the test data to a tensor\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 200 does not match index length 460",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalePrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the predictions to predictions.csv\u001b[39;00m\n\u001b[1;32m      8\u001b[0m predictions_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 200 does not match index length 460"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Id': test_df['Id'].astype(int),\n",
    "    'SalePrice': predictions_np.flatten().astype(float)\n",
    "})\n",
    "\n",
    "# Save the predictions to predictions.csv\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
